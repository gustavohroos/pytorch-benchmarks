# -*- coding: utf-8 -*-
"""Benchmarks.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bJf1rZIjSGy45WByDuWWMUFYz_QmSV-f
"""

from PIL import Image
from tqdm import tqdm
from io import BytesIO
import os
import torch
import torchvision
import requests
from tqdm import tqdm
import argparse
import time
import pandas as pd
from torchvision.models import resnet18, ResNet18_Weights, \
                               resnet34, ResNet34_Weights, \
                               resnet50, ResNet50_Weights, \
                               resnet101, ResNet101_Weights, \
                               resnet152, ResNet152_Weights, \
                               mobilenet_v2, MobileNet_V2_Weights, \
                               mobilenet_v3_small, MobileNet_V3_Small_Weights, \
                               mobilenet_v3_large, MobileNet_V3_Large_Weights, \
                               efficientnet_b0, EfficientNet_B0_Weights, \
                               efficientnet_b3, EfficientNet_B3_Weights, \
                               efficientnet_b7, EfficientNet_B7_Weights, \
                               inception_v3, Inception_V3_Weights, \
                               googlenet, GoogLeNet_Weights


def main(args):

    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
    print(f"Running on: {device}")

    models_to_build_list = [
        [resnet18, ResNet18_Weights],
        [resnet34, ResNet34_Weights],
        [resnet50, ResNet50_Weights],
        [resnet101, ResNet101_Weights],
        [resnet152, ResNet152_Weights],
        [mobilenet_v2, MobileNet_V2_Weights],
        [mobilenet_v3_small, MobileNet_V3_Small_Weights],
        [mobilenet_v3_large, MobileNet_V3_Large_Weights],
        [efficientnet_b0, EfficientNet_B0_Weights],
        [efficientnet_b3, EfficientNet_B3_Weights],
        [efficientnet_b7, EfficientNet_B7_Weights],
        [inception_v3, Inception_V3_Weights],
        [googlenet, GoogLeNet_Weights],
    ]

    weights_list = []
    preprocess_list = []
    models_list = []

    for model_to_build in models_to_build_list:
        try:
            weights = model_to_build[1].IMAGENET1K_V2
        except:
            weights = model_to_build[1].IMAGENET1K_V1
        preprocess = weights.transforms().to(device)
        weights_list.append(weights)
        preprocess_list.append(preprocess)
        model = model_to_build[0](weights=weights).to(device)
        model.eval()
        models_list.append(model)

    api_token = os.environ.get("HF_API_TOKEN")

    offset = 0
    headers = {"Authorization": f"Bearer {api_token}"}
    rows = []


    API_URL = f"https://datasets-server.huggingface.co/first-rows?dataset=imagenet-1k&config=default&split=validation"
    response = requests.get(API_URL, headers=headers)
    offset += 100
    if response.status_code == 200:
        rows.extend(response.json()["rows"])

    images = []
    labels = []

    def load_dataset(rows):
        response_labels = [row['row']['label'] for row in rows]
        for label in response_labels:
            if os.path.exists(f"images/image_{label}.jpg"):
                rows = [row for row in rows if row['row']['label'] != label]
    
        for row in rows:
            image = requests.get(row['row']['image']['src']).content
            label = row['row']['label']

            try:
                image_buffer = BytesIO(image)
                img = Image.open(image_buffer)
                img.save(f"images/image_{label}.jpg")
            except Exception as e:
                print("Error:", e)

        images = []
        labels = []

        for im in os.listdir('images'):
            if not im.endswith('.jpg'):
                continue
            img = Image.open(f"images/{im}")
            images.append(img)
            labels.append(int(im.split('_')[1].split('.')[0]))

        for index, image in enumerate(images):
            if image.mode != 'RGB':
                images.remove(image)
                labels.pop(index)

        return images, labels



    x, y = load_dataset(rows)

    images.extend(x)
    labels.extend(y)

    assert len(images) == len(labels)

    df = pd.DataFrame({'model': [], 'acc': [], 'time': [], 'batch_size': []})

    model = models_list[args.index]
    preprocess = preprocess_list[args.index]

    batches = create_batches(images, labels, args.batch_size, preprocess, model, device)

    with torch.no_grad():
        right = 0
        start = time.time()
        for batch in tqdm(batches):
            x, y = zip(*batch)

            x = torch.stack(x).to(device)

            prediction = model(x).softmax(1)

            class_id = prediction.argmax(1)

            for i in range(len(class_id)):
                if class_id[i] == y[i]:
                    right += 1

        total_time = time.time() - start
        accuracy = right/(len(images))

        df = pd.concat([df, pd.DataFrame([{'model': str(args.index), 'acc': accuracy, 'time': total_time, 'batch_size': str(args.batch_size)}])], ignore_index=True)

    with open("report.csv", "a") as f:
        df.to_csv(f, header=False, index=False)

def create_batches(images, labels, batch_size, preprocess, model, device):
    batches = []
    batch = []
    for image, label in zip(images, labels):
        image = preprocess(image).to(device)
        batch.append((image, label))
        if len(batch) == batch_size:
            batches.append(batch)
            batch = []

    if len(batch) > 0:
        batches.append(batch)

    return batches

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Model index.')
    parser.add_argument('--index', type=int,
                        help='Model index')
    parser.add_argument('--batch-size', type=int, default=1,
                        help='Batch size')
    args = parser.parse_args()
    main(args)

