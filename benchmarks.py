# -*- coding: utf-8 -*-
"""Benchmarks.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bJf1rZIjSGy45WByDuWWMUFYz_QmSV-f
"""

from PIL import Image
from io import BytesIO
import os
import torch
import requests
import argparse
import time
import pandas as pd
from memory_profiler import memory_usage
from torchvision.models import resnet18, ResNet18_Weights, \
                               resnet34, ResNet34_Weights, \
                               resnet50, ResNet50_Weights, \
                               resnet101, ResNet101_Weights, \
                               resnet152, ResNet152_Weights, \
                               mobilenet_v2, MobileNet_V2_Weights, \
                               mobilenet_v3_small, MobileNet_V3_Small_Weights, \
                               mobilenet_v3_large, MobileNet_V3_Large_Weights, \
                               efficientnet_b0, EfficientNet_B0_Weights, \
                               efficientnet_b3, EfficientNet_B3_Weights, \
                               efficientnet_b7, EfficientNet_B7_Weights, \
                               inception_v3, Inception_V3_Weights, \
                               googlenet, GoogLeNet_Weights


accuracy = 0
total_time = 0
models_to_build_list = [
    [resnet18, ResNet18_Weights],
    [resnet34, ResNet34_Weights],
    [resnet50, ResNet50_Weights],
    [resnet101, ResNet101_Weights],
    [resnet152, ResNet152_Weights],
    [mobilenet_v2, MobileNet_V2_Weights],
    [mobilenet_v3_small, MobileNet_V3_Small_Weights],
    [mobilenet_v3_large, MobileNet_V3_Large_Weights],
    [efficientnet_b0, EfficientNet_B0_Weights],
    [efficientnet_b3, EfficientNet_B3_Weights],
    [efficientnet_b7, EfficientNet_B7_Weights],
    [inception_v3, Inception_V3_Weights],
    [googlenet, GoogLeNet_Weights],
]
def main(args):
    global accuracy
    global total_time

    def create_batches(images, labels, batch_size, preprocess, model, device):
        batches = []
        batch = []
        for image, label in zip(images, labels):
            image = preprocess(image).to(device)
            batch.append((image, label))
            if len(batch) == batch_size:
                batches.append(batch)
                batch = []

        if len(batch) > 0:
            batches.append(batch)

        return batches

    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

    model_to_build = models_to_build_list[args.index]
    try:
        weights = model_to_build[1].IMAGENET1K_V2
    except:
        weights = model_to_build[1].IMAGENET1K_V1
    preprocess = weights.transforms().to(device)
    model = model_to_build[0](weights=weights).to(device)
    model.eval()

    api_token = os.environ.get("HF_API_TOKEN")

    offset = 0
    headers = {"Authorization": f"Bearer {api_token}"}
    rows = []

    API_URL = f"https://datasets-server.huggingface.co/first-rows?dataset=imagenet-1k&config=default&split=validation"
    response = requests.get(API_URL, headers=headers)
    offset += 100
    if response.status_code == 200:
        rows.extend(response.json()["rows"])

    images = []
    labels = []

    def load_dataset(rows):
        response_labels = [row['row']['label'] for row in rows]
        for label in response_labels:
            if os.path.exists(f"images/image_{label}.jpg"):
                rows = [row for row in rows if row['row']['label'] != label]
    
        for row in rows:
            image = requests.get(row['row']['image']['src']).content
            label = row['row']['label']

            try:
                image_buffer = BytesIO(image)
                img = Image.open(image_buffer)
                img.save(f"images/image_{label}.jpg")
            except Exception as e:
                print("Error:", e)

        images = []
        labels = []

        for im in os.listdir('images'):
            if not im.endswith('.jpg'):
                continue
            img = Image.open(f"images/{im}")
            images.append(img)
            labels.append(int(im.split('_')[1].split('.')[0]))

        for index, image in enumerate(images):
            if image.mode != 'RGB':
                images.remove(image)
                labels.pop(index)

        return images, labels



    x, y = load_dataset(rows)

    images.extend(x)
    labels.extend(y)

    assert len(images) == len(labels)

    batches = create_batches(images, labels, args.batch_size, preprocess, model, device)

    start = time.time()
    with torch.no_grad():
        right = 0
        for batch in batches:
            x, y = zip(*batch)

            x = torch.stack(x).to(device)

            prediction = model(x).softmax(1)

            class_id = prediction.argmax(1)

            for i in range(len(class_id)):
                if class_id[i] == y[i]:
                    right += 1

    total_time = time.time() - start
    accuracy = right/(len(images))


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Model index.')
    parser.add_argument('--index', type=int,
                        help='Model index')
    parser.add_argument('--batch-size', type=int, default=1,
                        help='Batch size')
    args = parser.parse_args()
    top_mem = memory_usage((main, (args,),), max_usage=True, interval=1, timeout=1000)

    df = pd.DataFrame({'model': [], 'acc': [], 'time': [], 'batch_size': [], 'max_memory_usage': [], 'mean_power_consumption': []})

    df = pd.concat([df, pd.DataFrame([{'model': str(args.index), 
                                       'acc': accuracy, 
                                       'time': total_time, 
                                       'batch_size': str(args.batch_size),
                                       'max_memory_usage': top_mem}])], ignore_index=True)

    if os.path.exists('results.csv'):
        df = pd.concat([pd.read_csv('results.csv'), df], ignore_index=True)
        pd.DataFrame(df).to_csv('results.csv', index=False)
    else:
        df.to_csv('results.csv', index=False)

